在这一部分，我们来一步步讲解“模型利用梯度下降更新参数”的过程。我们会从最基础的迭代计算开始，逐步过渡到机器学习和深度学习中的应用，并结合公式帮助你理解。

\subsection{从基础的迭代计算开始}

假设我们有一个我们有一个函数 \(f_{\bm{\theta}} \left( \cdot \right)\)，我们希望找到使这个函数取得最小值的 \(\bm{\theta}\) 值。
一般来说都会使用梯度下降法，其核心思想包括：
\begin{itemize}
    \item 计算当前点的梯度 \(\nabla f_{\bm{\theta}}\)：梯度表示函数在该点的变化率，指明函数增长最快的方向。
    \item 沿着梯度的反方向更新参数：因为我们希望最小化函数值，所以要朝着函数下降最快的方向前进。
    \item 更新参数：重复以上两步，直到收敛通过迭代不断调整 \(\bm{\theta}\) 的值，使函数值逐步减小，直到达到最小值。
\end{itemize}
更新公式如下：
\begin{equation}\label{eq:gradient_descent_iterative_update}
    \triangle \bm{\theta} \coloneq \bm{\theta}^{t+1} - \bm{\theta}^{t} = - \eta \nabla f_{\bm{\theta}}
\end{equation}
其中，\(\alpha\) 是学习率，控制每次更新的步长。\(\nabla f_{\bm{\theta}}\) 是具有参数函数 \(\bm{\theta}\) 的函数 \(f_{\bm{\theta}} \left(x\right)\) 在点 \(\bm{\theta}\) 处的梯度。

\subsection{机器学习中的梯度下降}

在机器学习与深度学习中，我们的目标是训练一个模型，使其在给定输入 \(\bm{\mathsf{x}}\) 时，输出预测值 \(\hat{\bm{\mathsf{y}}}\)，并尽可能接近真实值 \(\bm{\mathsf{y}}\)。
此时，函数 \(f_{\bm{\theta}}\) 本身是模型的预测函数，我们不能直接使用模型预测函数 \(f_{\bm{\theta}}\) 的梯度来优化模型参数，因为 \(f_{\bm{\theta}}\) 的梯度 \(\eta \nabla f_{\bm{\theta}}\) 反映的是输出对输入的敏感度，而不是模型性能的衡量。
所以，我们需要引入一个损失函数（loss function） \(\mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{x}} \right), \bm{\mathsf{y}} \right) \)，衡量预测值与真实值之间的差距。
所以公式 (\ref{eq:gradient_descent_iterative_update}) 可以改写为：
\begin{equation}\label{eq:GD-loss_iterative_update}
    \triangle \bm{\theta} \coloneq \bm{\theta}^{t+1} - \bm{\theta}^{t} = - \eta \left[ \nabla_{\bm{\theta}} \mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{x}} \right), \bm{\mathsf{y}} \right) \right]^{\top}
\end{equation}
设 \(\bm{\theta} \in \mathbb{R}^{D}\)，则 \(\mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{x}} \right), \bm{\mathsf{y}} \right) \in \mathbb{R}\)，并且 \(\nabla_{\bm{\theta}} \mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{x}} \right), \bm{\mathsf{y}} \right) \in \mathbb{R}^{1 \times D}\)。

\subsection{常见的损失函数}

在最小化损失函数中，一般会有三种比较核心的优化算法：
\begin{itemize}
    \item \textbf{随机梯度下降（Stochastic Gradient Descent, SGD}：每次迭代只使用一个样本来计算梯度，更新速度快，但可能会有较大的波动。
    \item \textbf{批量梯度下降（Batch Gradient Descent）}：每次迭代使用整个训练集来计算梯度，收敛稳定，但计算开销大。
    \item \textbf{小批量梯度下降（Mini-batch Gradient Descent）}：每次迭代使用一小部分样本来计算梯度，兼顾了速度和稳定性，是最常用的方式。
\end{itemize}

接下来，我们以批量梯度下降为例，展示总共 \(N\) 个采样对集合 \(\left( \bm{\mathsf{X}}, \bm{\mathsf{Y}} \right) = \left\{ \left( \bm{\mathsf{x}}^{(1)}, \bm{\mathsf{y}}^{(1)} \right), \left( \bm{\mathsf{x}}^{(2)}, \bm{\mathsf{y}}^{(2)} \right), \dots, \left( \bm{\mathsf{x}}^{(N)}, \bm{\mathsf{y}}^{(N)} \right) \right\}\) 的损失函数。

\subsubsection{回归任务}

例如，回归任务中的均方误差（Mean Squared Error, MSE）：
\[
    \mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{X}} \right), \bm{\mathsf{Y}} \right) = \frac{1}{N} \sum_{i=1}^{N} \left( \hat{\bm{\mathsf{y}}}^{(i)} - \bm{\mathsf{y}}^{(i)} \right)^2
\]
其中 \(f_{\bm{\theta}} \left( \bm{\mathsf{x}}^{(i)} \right) = \hat{\bm{\mathsf{y}}}^{(i)}\)，均方误差（MSE）可以理解为最小化预测值和实际值之间的欧几里得距离（Euclidean distance）的平方。

\subsubsection{分类任务}

或者分类任务中的交叉熵（Cross-Entropy）损失函数：
\[
    \mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{X}} \right), \bm{\mathsf{Y}} \right) = -\frac{1}{N} \sum_{i=1}^{N} \left( \bm{\mathsf{y}}^{(i)} \log \hat{\bm{\mathsf{y}}}^{(i)} + \left( 1 - \bm{\mathsf{y}}^{(i)} \right) \log \left( 1 - \hat{\bm{\mathsf{y}}}^{(i)} \right) \right)
\]
多分类（一共 \(L\) 个类） ：
\begin{equation}\label{eq:cross_entropy_loss}
    \mathcal{L} \left( f_{\bm{\theta}} \left( \bm{\mathsf{X}} \right), \bm{\mathsf{Y}} \right) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{L} y^{(i)}_{j} \log \hat{y}^{(i)}_{j}
\end{equation}
\(y^{(i)}_{j}\) 是样本 \(\bm{\mathsf{x}}^{(i)}\) 的 one-hot 编码中第 \(j\) 个类别的标签（\(0\) 或 \(1\)），\(\hat{y}^{(i)}_{j}\) 是模型对样本 \(\bm{\mathsf{x}}^{(i)}\) 的预测是第 \(j\) 个分类的概率。

\rcomment[\textbf{为什么交叉熵是这种形式？}]{
在此，我们需要了解 \textbf{为什么交叉熵是这种形式}？
从机器学习角度看，\textbf{最小化模型损失函数的交叉熵等价于最大化概率模型的最大似然估计（Maximum Likelihood Estimation，MLE）}。

首先，我们要了解：\textbf{什么是似然（likelihood）}？
似然，你可以理解为是指在给定模型参数的情况下，观察到数据的概率有多大。

我们再回来看我们要解决的问题：\textbf{怎样调整参数 \(\bm{\theta}\) 最大化整个数据集上模型预测的联合概率（似然）}：
\[
    \prod_{i=1}^{N} P \left( \bm{\mathsf{y}}^{(i)} \mid \bm{\mathsf{x}}^{(i)}; \bm{\theta} \right)
\]
翻译成人话就是 \textbf{我们希望通过调整参数 \(\bm{\theta}\)，使得最大化模型预测的输出 \(\hat{\bm{\mathsf{y}}}^{(i)}\) 是每个样本的真实标签 \(\bm{\mathsf{y}}^{(i)}\) 的概率}。
接着我们可以对两侧取对数，得到：
\[
    \sum_{i=1}^{N} \log P \left( \bm{\mathsf{y}}^{(i)} \mid \bm{\mathsf{x}}^{(i)}; \bm{\theta} \right)
\]

注意，我们以多分类任务为例，模型输出的每个类别的概率为：
\[
    \hat{\bm{\mathsf{y}}} = \left[ \hat{y}_{1}, \hat{y}_{2}, \dots, \hat{y}_{L} \right], \quad \sum_{j=1}^{L} \hat{y}_{j} = 1
\]

通常真实标签 \(\bm{\mathsf{y}}\) 是 one-hot 编码的形式：
\[
    \bm{\mathsf{y}} = \left[ y_{1}, y_{2}, \dots, y_{L} \right], \quad y_{i} \in \left\{ 0, 1 \right\}, \quad \sum_{j=1}^{L} y_{j} = 1
\]
那么对于每个样本 \(\left(\bm{\mathsf{x}}, \bm{\mathsf{y}} \right)\) 的对数似然是：
\[
    \log P \left( \bm{\mathsf{y}} \mid \bm{\mathsf{x}}; \bm{\theta} \right) = \sum_{j=1}^{L} y_{j} \log \hat{y}_{j}
\]

考虑所有的样本，并且 one-hot 编码的特性，最大化最大似然估计目标就变成了：
\[
    \underset{\bm{\theta}}{\arg \max} \sum_{i=1}^{N} \sum_{j=1}^{L} {y}^{(i)}_{j} \log \hat{y}^{(i)}_{j}  
\]

加一个负号，我们就得到了交叉熵损失函数（最小化的目标）：
\[
    \underset{\bm{\theta}}{\arg \min} - \sum_{i=1}^{N} \sum_{j=1}^{L} {y}^{(i)}_{j} \log \hat{y}^{(i)}_{j}
\]
这就是我们交叉熵（Cross-Entropy）的 loss 函数的来源。
}