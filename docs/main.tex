\documentclass[citestyle=gb7714-2015, bibstyle=gb7714-2015,lang=cn,14pt,scheme=chinese]{elegantbook}

\title{深度学习模型的学习动态}
\subtitle{xxxxx}

\author{姜广琛}
\institute{西北工业大学}
\date{2025/04/17}
\version{0.1}
% \bioinfo{自定义}{信息}

% \extrainfo{注意：本模板自 2023 年 1 月 1 日开始，不再更新和维护！}

\setcounter{tocdepth}{3}

\logo{logo-blue.png}
\cover{cover.jpg}

% 本文档命令




% 修改标题页的橙色带
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}

\addbibresource[location=local]{reference.bib} % 参考文献，不要删除
\ExecuteBibliographyOptions{sorting=ynt}

\begin{document}

% \maketitle
% \frontmatter

% \tableofcontents

\mainmatter%

\chapter{环境设置}

\section{扫地机器人（Sweeping Robot）}

\begin{definition*}{环境描述}
\# 问题描述

    设计一个扫地机器人环境，模拟机器人在 \(5 \times 5\) 的离散网格中进行自主清扫与充电的任务。该环境共有 \(5 \times 5 = 25\) 个格子，构成了机器人的观测空间。机器人（Agent）是主要的控制对象，能够在这些格子之间进行移动。为了增加任务的复杂性和趣味性，环境中还包含了多个元素，包括垃圾、充电桩和障碍物，每个元素的设置都会影响机器人的行为决策。

\# 在这个环境中有以下组成部分：
    \begin{itemize}
        \item 垃圾 (Trash): 位于网格的 \(\left( 5, 4 \right)\)（索引从 \(1\) 开始）。当机器人到达这个位置时，获得 \(+5\) 奖励，回合结束。
        \item 充电桩 (Charger): 位于网格的 （索引从 \(1\) 开始）。当机器人到达这个位置时，获得 \(+1\) 奖励，回合结束。
        \item 障碍物 (Obstacle): 位于网格的 \(\left( 3, 3 \right)\)（索引从 \(1\) 开始）。机器人无法进入该格子。
    \end{itemize}

\# 这个环境中有以下限制：
\begin{itemize}
    \item 网格大小为 \(5 \times 5 = 25\)，机器人只能在该网格内移动。
    \item 在每回合，机器人随机出生在 \(5 \times 5 = 25\) 的网格内的任意一空白随机点。
    \item 机器人每次可以选择向上、下、左或右移动一个格子。
    \item 对于障碍物所在的位置，机器人无法进入该位置。
    \item 每当机器人到达垃圾或充电桩时，回合结束。
\end{itemize}
\end{definition*}

\begin{theorem*}{组成规则}
    \# 在这个环境中有以下组成部分：
    \begin{itemize}
        \item 垃圾 (Trash): 位于网格的 \(\left( 5, 4 \right)\)（索引从 \(1\) 开始）。当机器人到达这个位置时，获得 \(+5\) 奖励，回合结束。
        \item 充电桩 (Charger): 位于网格的 （索引从 \(1\) 开始）。当机器人到达这个位置时，获得 \(+1\) 奖励，回合结束。
        \item 障碍物 (Obstacle): 位于网格的 \(\left( 3, 3 \right)\)（索引从 \(1\) 开始）。机器人无法进入该格子。
    \end{itemize}
\end{theorem*}

\begin{proposition*}{环境限制}
    
\end{proposition*}

\section{多开关匹配}

\begin{definition*}{环境描述}
    sdasdad asd
\end{definition*}

\section{Double Mountain Car}

\begin{definition*}{环境描述}
\# 问题描述

    设计一个包含 两个山地车 的强化学习环境。该环境是经典离散动作的 MountainCar 问题的扩展版本~\footnote{如果你不熟悉 MountainCar 问题，请参考 \href{https://gymnasium.farama.org/environments/classic_control/mountain_car}{https://gymnasium.farama.org/environments/classic\_control/mountain\_car}。}，两个智能体（小车）必须协作，利用加速度在重力势能影响下成功爬坡，到达目标位置。两个小车可以分别独立控制，它们的任务是同时达到终点位置的目标状态，回合才会终止。这个问题与 MountainCar 问题几乎一致，但是可以帮助大家熟悉 gymnasium 库中的 \href{https://gymnasium.farama.org/api/spaces/fundamental/#gymnasium.spaces.Box}{spaces.Box} 和 \href{https://gymnasium.farama.org/api/spaces/fundamental/#gymnasium.spaces.MultiDiscrete}{spaces.MultiDiscrete} 这两个基础空间类。

\# 具体要求

对于这个问题的相关具体要求，可以仔细阅读并参考 MountainCar 问题的源代码 \href{https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/mountain_car.py}{gymnasium/envs/classic\_control/mountain\_car.py}。
我们唯一需要做的事情就是将原本单个 Car 的状态空间与动作空间变成 两个 Car 的状态与动作空间。
熟悉相关基础类，并初步入门多智能体控制。
\end{definition*}

\chapter{实验过程及结果}

\section{SARAS}

\section{Policy Gradient}

\section{\(Q\)-Learning}

\section{PPO}



\nocite{*}

\printbibliography[heading=bibintoc, title=\ebibname]
\appendix

\chapter{appendix}

\end{document}
